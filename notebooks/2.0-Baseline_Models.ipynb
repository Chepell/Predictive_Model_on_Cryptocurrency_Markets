{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "### Базовые модели на основе цены закрытия (трасформированной до логарифмического прироста):\n",
    "- Наивный прогноз\n",
    "- Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import Handlers as hd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "import optuna\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = 'pandas')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных\n",
    "используется файл обработанных данных, в котором:\n",
    "- удален начальный, нерелевантный, период\n",
    "- обработаны пропуски\n",
    "- произведена трансформация признаков\n",
    "- сгенерированны новые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оставляю в качестве признака только Log_Return и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"Long\"\n",
    "df = pd.read_parquet(\n",
    "    \"../data/ETH-Full-1H_prepared.parquet\", columns=[\"Close_log_return\", TARGET]\n",
    ")\n",
    "df = df.asfreq(\"H\")  # установка периода для timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 45120 entries, 2018-03-01 00:00:00 to 2023-04-23 23:00:00\n",
      "Freq: H\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Close_log_return  45120 non-null  float64\n",
      " 1   Long              45120 non-null  int32  \n",
      "dtypes: float64(1), int32(1)\n",
      "memory usage: 881.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform TimeSeries to Dataset for Supervised Learning\n",
    "Определяется глубина последовательности данных T, которая будет использоваться для построения прогноза. Временное окно в прошлое.\n",
    "\n",
    "Выбираю 6 часовое окно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create $X$, $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, N, D = hd.create_X_y_from_timeseries(df, TARGET, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (45114, 6) y.shape: (45114,) N: 45114 D: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape:\", X.shape, \"y.shape:\", y.shape, \"N:\", N, \"D:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "Разбиение с стратифиацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data\n",
    "\n",
    "В данном случае, т.к. один признак используется для baseline автокорреляционной модели, то в скалировании нет необходимости.\n",
    "\n",
    "В дальнейшем, нужно скалировать признаки, приводить их к одному масштабу. Путем перебора выбирать лучший скалер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный прогноз\n",
    "### Просто предсказание значения классом большинства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAIN ***\n",
      "Accuracy: 0.910\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F1: 0.000\n",
      "ROC AUC: 0.500\n",
      "\n",
      "*** TEST ***\n",
      "Accuracy: 0.910\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F1: 0.000\n",
      "ROC AUC: 0.500\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.zeros(len(X_train))\n",
    "y_test_pred = np.zeros(len(X_test))\n",
    "\n",
    "hd.print_classification_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если смотреть по Accuracy, то вполне ок ) Предсказаны все объекты класса 0.\n",
    "\n",
    "А все остальные метрики говорят, что модель плохая.\n",
    "\n",
    "А значение ROC AUC = 0.5 говорит, что модель работает на уровне случайного угадывания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n",
    "### С гиперпараметрами по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAIN ***\n",
      "Accuracy: 0.910\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F1: 0.000\n",
      "ROC AUC: 0.500\n",
      "\n",
      "*** TEST ***\n",
      "Accuracy: 0.910\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F1: 0.000\n",
      "ROC AUC: 0.500\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "hd.print_classification_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за несбалансированности классов все ушло в предсказание класса 0. \n",
    "\n",
    "Результат такой же как и для наивного прогноза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n",
    "### С взвешиванием классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAIN ***\n",
      "Accuracy: 0.530\n",
      "Precision: 0.101\n",
      "Recall: 0.533\n",
      "F1: 0.170\n",
      "ROC AUC: 0.531\n",
      "\n",
      "*** TEST ***\n",
      "Accuracy: 0.531\n",
      "Precision: 0.104\n",
      "Recall: 0.548\n",
      "F1: 0.174\n",
      "ROC AUC: 0.539\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "hd.print_classification_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат чуть лучше чем случайный. Возьмем его за Baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляю выбор скалера в пайплайн через кастомный трансформер, где конкретный тип скалера выбирается в рамках GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'scaler__name': 'standard'}\n",
      "Best score: 0.16731642517896658\n",
      "*** TRAIN ***\n",
      "Accuracy: 0.530\n",
      "Precision: 0.101\n",
      "Recall: 0.534\n",
      "F1: 0.170\n",
      "ROC AUC: 0.532\n",
      "\n",
      "*** TEST ***\n",
      "Accuracy: 0.530\n",
      "Precision: 0.103\n",
      "Recall: 0.545\n",
      "F1: 0.173\n",
      "ROC AUC: 0.537\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", hd.SelectScaler(name=\"standart\")),\n",
    "        (\"classifier\", LogisticRegression(max_iter=10000, class_weight=\"balanced\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"scaler__name\": [\"standard\", \"minmax\", \"robust\", \"mean_normalization\", \"no_scaler\"],\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=skf, scoring=\"f1\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = grid_search.predict(X_train)\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "hd.print_classification_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision на тестовой выборке еще немного вырос c 0.096 до 0.098"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование Optuna для подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X=X_train, y=y_train):\n",
    "    penalty_solver_combo = trial.suggest_categorical(\n",
    "        \"penalty_solver\",\n",
    "        [\n",
    "            (\"l1\", \"liblinear\"),\n",
    "            (\"l1\", \"saga\"),\n",
    "            (\"l2\", \"newton-cg\"),\n",
    "            (\"l2\", \"lbfgs\"),\n",
    "            (\"l2\", \"liblinear\"),\n",
    "            (\"l2\", \"sag\"),\n",
    "            (\"l2\", \"saga\"),\n",
    "            (\"none\", \"newton-cg\"),\n",
    "            (\"none\", \"lbfgs\"),\n",
    "            (\"none\", \"sag\"),\n",
    "            (\"none\", \"saga\"),\n",
    "        ],\n",
    "    )\n",
    "    penalty = penalty_solver_combo[0]\n",
    "    solver = penalty_solver_combo[1]\n",
    "\n",
    "    C = trial.suggest_float(\"classifier__C\", 0.01, 1)\n",
    "    max_iter = trial.suggest_int(\"classifier__max_iter\", 50, 5000)\n",
    "\n",
    "    name = trial.suggest_categorical(\n",
    "        \"scaler__name\",\n",
    "        [\"standard\", \"minmax\", \"robust\", \"mean_normalization\", \"no_scaler\"],\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", hd.SelectScaler(name=name)),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    C=C,\n",
    "                    penalty=penalty,\n",
    "                    solver=solver,\n",
    "                    max_iter=max_iter,\n",
    "                    class_weight=\"balanced\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    cv_metrics = cross_validate(\n",
    "        estimator=pipe,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        cv=skf,\n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    score = np.mean(cv_metrics[\"test_score\"])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-30 15:42:38,947] A new study created in memory with name: LogisticRegression\n",
      "[I 2023-08-30 15:42:41,554] Trial 0 finished with value: 0.16772873191800888 and parameters: {'penalty_solver': ('l2', 'saga'), 'classifier__C': 0.48664718674767365, 'classifier__max_iter': 2248, 'scaler__name': 'no_scaler'}. Best is trial 0 with value: 0.16772873191800888.\n",
      "[I 2023-08-30 15:42:46,769] Trial 1 finished with value: 0.1697172644099565 and parameters: {'penalty_solver': ('l2', 'saga'), 'classifier__C': 0.5029569509069058, 'classifier__max_iter': 4480, 'scaler__name': 'standard'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:42:47,406] Trial 2 finished with value: 0.16940205311284118 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.7800046272205047, 'classifier__max_iter': 3198, 'scaler__name': 'minmax'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:11,394] Trial 3 finished with value: 0.1668771167597812 and parameters: {'penalty_solver': ('l1', 'saga'), 'classifier__C': 0.7064412141793373, 'classifier__max_iter': 3925, 'scaler__name': 'minmax'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:12,593] Trial 4 finished with value: 0.1697172644099565 and parameters: {'penalty_solver': ('none', 'newton-cg'), 'classifier__C': 0.19372682621855633, 'classifier__max_iter': 4249, 'scaler__name': 'robust'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:13,842] Trial 5 finished with value: 0.1697172644099565 and parameters: {'penalty_solver': ('none', 'newton-cg'), 'classifier__C': 0.2695628981724164, 'classifier__max_iter': 878, 'scaler__name': 'standard'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:14,342] Trial 6 finished with value: 0.16970701775157318 and parameters: {'penalty_solver': ('l2', 'lbfgs'), 'classifier__C': 0.09042561392725389, 'classifier__max_iter': 3258, 'scaler__name': 'robust'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:14,857] Trial 7 finished with value: 0.16900831595299015 and parameters: {'penalty_solver': ('l2', 'lbfgs'), 'classifier__C': 0.8493425338269449, 'classifier__max_iter': 2385, 'scaler__name': 'minmax'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:15,529] Trial 8 finished with value: 0.16931130652684573 and parameters: {'penalty_solver': ('l1', 'liblinear'), 'classifier__C': 0.41162566555204927, 'classifier__max_iter': 4821, 'scaler__name': 'standard'}. Best is trial 1 with value: 0.1697172644099565.\n",
      "[I 2023-08-30 15:46:15,920] Trial 9 finished with value: 0.16842250468024772 and parameters: {'penalty_solver': ('l2', 'lbfgs'), 'classifier__C': 0.9889778635039003, 'classifier__max_iter': 3726, 'scaler__name': 'no_scaler'}. Best is trial 1 with value: 0.1697172644099565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 value: 0.1697172644099565\n",
      "Best params: {'penalty_solver': ('l2', 'saga'), 'classifier__C': 0.5029569509069058, 'classifier__max_iter': 4480, 'scaler__name': 'standard'}\n",
      "CPU times: total: 203 ms\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(study_name='LogisticRegression', direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Best f1 value:', study.best_value)\n",
    "print('Best params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-30 16:05:15,763] Trial 50 finished with value: 0.16846738669540814 and parameters: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.16571074661921179, 'classifier__max_iter': 2317, 'scaler__name': 'mean_normalization'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:05:16,417] Trial 51 finished with value: 0.16981766730331777 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.10170544083151214, 'classifier__max_iter': 2604, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:05:17,089] Trial 52 finished with value: 0.16969655617104823 and parameters: {'penalty_solver': ('l2', 'lbfgs'), 'classifier__C': 0.049511411546401374, 'classifier__max_iter': 3137, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:03,325] Trial 53 finished with value: 0.16943931663095194 and parameters: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.0957749769754497, 'classifier__max_iter': 1336, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:03,901] Trial 54 finished with value: 0.16981766730331777 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.039461578666086794, 'classifier__max_iter': 2414, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:10,610] Trial 55 finished with value: 0.16951616374738282 and parameters: {'penalty_solver': ('l1', 'saga'), 'classifier__C': 0.19468477064666434, 'classifier__max_iter': 2046, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:11,324] Trial 56 finished with value: 0.16972994039613637 and parameters: {'penalty_solver': ('l1', 'liblinear'), 'classifier__C': 0.12694087172851065, 'classifier__max_iter': 2908, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:16,900] Trial 57 finished with value: 0.1697172644099565 and parameters: {'penalty_solver': ('none', 'saga'), 'classifier__C': 0.09119045244618168, 'classifier__max_iter': 164, 'scaler__name': 'standard'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:18,029] Trial 58 finished with value: 0.1697172644099565 and parameters: {'penalty_solver': ('none', 'newton-cg'), 'classifier__C': 0.1629621336365638, 'classifier__max_iter': 619, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:21,849] Trial 59 finished with value: 0.1697792987812427 and parameters: {'penalty_solver': ('l2', 'saga'), 'classifier__C': 0.011690147801660694, 'classifier__max_iter': 1814, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:22,356] Trial 60 finished with value: 0.16954348085383358 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.27697969138781314, 'classifier__max_iter': 3684, 'scaler__name': 'no_scaler'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:22,916] Trial 61 finished with value: 0.16981766730331777 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.03274436846197725, 'classifier__max_iter': 1137, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:23,418] Trial 62 finished with value: 0.16981766730331777 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.048165853312777465, 'classifier__max_iter': 1505, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:23,945] Trial 63 finished with value: 0.16981766730331777 and parameters: {'penalty_solver': ('none', 'lbfgs'), 'classifier__C': 0.07519890852060862, 'classifier__max_iter': 704, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:06:25,132] Trial 64 finished with value: 0.1697172644099565 and parameters: {'penalty_solver': ('l2', 'newton-cg'), 'classifier__C': 0.11762577092492263, 'classifier__max_iter': 2226, 'scaler__name': 'robust'}. Best is trial 48 with value: 0.16995007601651255.\n",
      "[I 2023-08-30 16:07:56,628] Trial 65 finished with value: 0.17047227893148664 and parameters: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.05704761580609944, 'classifier__max_iter': 2668, 'scaler__name': 'robust'}. Best is trial 65 with value: 0.17047227893148664.\n",
      "[I 2023-08-30 16:09:27,939] Trial 66 finished with value: 0.1687591976556325 and parameters: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.1351695424331666, 'classifier__max_iter': 2669, 'scaler__name': 'robust'}. Best is trial 65 with value: 0.17047227893148664.\n",
      "[I 2023-08-30 16:09:37,554] Trial 67 finished with value: 0.16764598786224624 and parameters: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.09035779388556502, 'classifier__max_iter': 2957, 'scaler__name': 'minmax'}. Best is trial 65 with value: 0.17047227893148664.\n",
      "[I 2023-08-30 16:11:25,642] Trial 68 finished with value: 0.16943896663736102 and parameters: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.06363470806098559, 'classifier__max_iter': 3264, 'scaler__name': 'robust'}. Best is trial 65 with value: 0.17047227893148664.\n",
      "[I 2023-08-30 16:12:47,602] Trial 69 finished with value: 0.1697911859422308 and parameters: {'penalty_solver': ('none', 'sag'), 'classifier__C': 0.17520031857121782, 'classifier__max_iter': 2441, 'scaler__name': 'mean_normalization'}. Best is trial 65 with value: 0.17047227893148664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 value: 0.17047227893148664\n",
      "Best params: {'penalty_solver': ('l2', 'sag'), 'classifier__C': 0.05704761580609944, 'classifier__max_iter': 2668, 'scaler__name': 'robust'}\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print('Best f1 value:', study.best_value)\n",
    "print('Best params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params.copy()\n",
    "\n",
    "if \"penalty_solver\" in best_params:\n",
    "    penalty, solver = best_params[\"penalty_solver\"]\n",
    "    best_params[\"classifier__penalty\"] = penalty\n",
    "    best_params[\"classifier__solver\"] = solver\n",
    "    del best_params[\"penalty_solver\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.05704761580609944,\n",
       " 'classifier__max_iter': 2668,\n",
       " 'scaler__name': 'robust',\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'sag'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params\n",
    "# Best f1 value: 0.26191126592125363\n",
    "# {'classifier__C': 0.5404716578189352,\n",
    "#  'classifier__max_iter': 3390,\n",
    "#  'scaler__name': 'minmax',\n",
    "#  'classifier__penalty': 'l2',\n",
    "#  'classifier__solver': 'sag'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'classifier__C': 0.05704761580609944,\n",
    " 'classifier__max_iter': 2668,\n",
    " 'scaler__name': 'robust',\n",
    " 'classifier__penalty': 'l2',\n",
    " 'classifier__solver': 'sag'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", hd.SelectScaler(name=\"no_scaler\")),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                class_weight=\"balanced\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, SelectScaler(name=&#x27;robust&#x27;)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(C=0.05704761580609944,\n",
       "                                    class_weight=&#x27;balanced&#x27;, max_iter=2668,\n",
       "                                    solver=&#x27;sag&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, SelectScaler(name=&#x27;robust&#x27;)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(C=0.05704761580609944,\n",
       "                                    class_weight=&#x27;balanced&#x27;, max_iter=2668,\n",
       "                                    solver=&#x27;sag&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectScaler</label><div class=\"sk-toggleable__content\"><pre>SelectScaler(name=&#x27;robust&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.05704761580609944, class_weight=&#x27;balanced&#x27;,\n",
       "                   max_iter=2668, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', SelectScaler(name='robust')),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.05704761580609944,\n",
       "                                    class_weight='balanced', max_iter=2668,\n",
       "                                    solver='sag'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the parameters in the pipeline\n",
    "pipe.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAIN ***\n",
      "Accuracy: 0.090\n",
      "Precision: 0.090\n",
      "Recall: 1.000\n",
      "F1: 0.166\n",
      "ROC AUC: 0.500\n",
      "\n",
      "*** TEST ***\n",
      "Accuracy: 0.090\n",
      "Precision: 0.090\n",
      "Recall: 1.000\n",
      "F1: 0.165\n",
      "ROC AUC: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "hd.print_classification_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрик стали немного лучше, чем при простом поиске по сетке с кросс-валидацией"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
